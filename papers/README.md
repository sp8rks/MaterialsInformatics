# Downloaded Papers for MSE 6640 Materials Informatics

This folder contains papers referenced in the course README, including both directly linked papers and foundational papers from blog posts.

## Successfully Downloaded Papers (19 total, ~53MB)

### Course-Referenced Papers
1. **paper_selfies.pdf** - SELFIES: A robust representation of semantically constrained graphs (1.4MB)
2. **paper_benchmark_overfitting.pdf** - Benchmark overfitting in materials informatics (2.5MB)
3. **paper_loco_cv.pdf** - LOCO-CV: Leave-one-cluster-out cross-validation (1.9MB)
4. **paper_ensemble_learning.pdf** - Ensemble learning in materials informatics (311KB)
5. **paper_extrapolation.pdf** - Extrapolation to extraordinary materials (811KB)
6. **paper_clustering.pdf** - Clustering in materials science (5.8MB)
7. **paper_unet.pdf** - U-Net: Convolutional Networks for Biomedical Image Segmentation (1.6MB)
8. **paper_nuclear_forensics.pdf** - Nuclear forensics with machine learning (811KB)
9. **paper_SAM.pdf** - Segment Anything Model (15MB)
10. **paper_domain_knowledge.pdf** - Is domain knowledge necessary for machine learning? (292KB)

### Foundational Papers from Blogs

#### Graph Neural Networks (from distill.pub/2021/gnn-intro/)
11. **GNN_relational_inductive_biases.pdf** - Relational inductive biases, deep learning, and graph networks (9.0MB)
    - arXiv: 1806.01261
12. **GNN_graph_attention_networks.pdf** - Graph Attention Networks (1.6MB)
    - arXiv: 1710.10903
13. **GNN_neural_message_passing.pdf** - Neural Message Passing for Quantum Chemistry (512KB)
    - arXiv: 1704.01212, ICML 2017

#### Transformers
14. **transformers_attention_is_all_you_need.pdf** - Attention Is All You Need (2.2MB)
    - arXiv: 1706.03762, Vaswani et al., 2017

#### Generative Models (VAE and GAN blogs)
15. **VAE_auto_encoding_variational_bayes.pdf** - Auto-Encoding Variational Bayes (3.8MB)
    - arXiv: 1312.6114, Kingma & Welling, 2013
16. **GAN_generative_adversarial_nets.pdf** - Generative Adversarial Nets (530KB)
    - arXiv: 1406.2661, Goodfellow et al., 2014

#### Deep Learning Fundamentals (CNN and RNN blogs)
17. **CNN_lecun_1998_gradient_based_learning.pdf** - Gradient-Based Learning Applied to Document Recognition (982KB)
    - LeCun et al., Proc. IEEE, 1998 (LeNet-5)
18. **LSTM_hochreiter_schmidhuber_1997.pdf** - Long Short-Term Memory (388KB)
    - Hochreiter & Schmidhuber, Neural Computation, 1997

#### Gaussian Processes
19. **gaussian_processes_rasmussen_williams_2006.pdf** - Gaussian Processes for Machine Learning (3.9MB)
    - Rasmussen & Williams, MIT Press, 2006 (Full book - freely available)

## Papers That Require Institutional Access (Not Downloaded)

The following papers are behind paywalls and could not be downloaded:
- **High Impact Research Areas in ML for MSE** - doi.org/10.1021/acs.chemmater.9b04078 (ACS)
- **Best Practices/Classification paper** - doi.org/10.1021/acs.chemmater.7b05304 (ACS)
- **Two-point statistics** - linkinghub.elsevier.com/retrieve/pii/S1359645408004886 (Elsevier)

These papers can be accessed through:
- University library subscriptions
- Direct publisher access if you have credentials
- ResearchGate or author-provided preprints

## Additional Resources

The course also references:
- **ISLP Book**: Introduction to Statistical Learning with Python - available at statlearning.com
- **Materials Project API**: next-gen.materialsproject.org/api
- **CrysTens Repository**: github.com/michaeldalverson/CrysTens

## Notes

- All papers are organized by topic for easy reference
- Papers from arXiv are freely available and can be re-downloaded if needed
- The Gaussian Processes book is officially freely distributed by MIT Press
- File naming convention: topic_shortname_year.pdf
