{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sp8rks/MaterialsInformatics/blob/main/worked_examples/support_vector_machines/SVM%20example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Example\n",
    "Support vector machines are often used for classification and regression tasks. They are particularly good for working within high dimensional spaces. They're memory efficeint and are robust to overfitting. However, they are computationally intensive, sensitive to noise, and can be hard to interpret. \n",
    "\n",
    "For this notebook I'll be pulling some data from Materials Project. I'll use the old api using my MyPymatgen virtual environment\n",
    "\n",
    "#### Video\n",
    "\n",
    "https://www.youtube.com/watch?v=ebTe3o6M0Bg&list=PLL0SWcFqypCl4lrzk1dMWwTUrzQZFt7y0&index=21 (Support Vector Machines)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Let's start by getting our API key loaded. This is important for use of the MPRester API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymatgen\n",
    "!pip install CBFV\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "%cd /content/drive/My Drive/teaching/5540-6640 Materials Informatics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get our API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "import os\n",
    "#if running locally\n",
    "#filename = r'G:\\My Drive\\teaching\\5540-6640 Materials Informatics\\old_apikey.txt'\n",
    "#if running google Colab\n",
    "filename = r'old_apikey.txt'\n",
    "\n",
    "def get_file_contents(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            # It's assumed our file contains a single line,\n",
    "            # with our API key\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(\"'%s' file not found\" % filename)\n",
    "\n",
    "\n",
    "Sparks_API = get_file_contents(filename)\n",
    "mpr = MPRester(Sparks_API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's grab some data to work with. We'll pick chlorides within 1 meV of the convex hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=('pretty_formula', 'band_gap',\n",
    "                           \"density\", 'formation_energy_per_atom', 'volume'))\n",
    "\n",
    "# grab some props for stable chlorides\n",
    "criteria = {'e_above_hull': {'$lte': 0.001},'elements':{'$all':['Cl']}}\n",
    "# criteria2 = {'e_above_hull': {'$lte': 0.02},'elements':{'$all':['O']},\n",
    "#              'band_gap':{'$ne':0}}\n",
    "\n",
    "props = ['pretty_formula', 'band_gap', \"density\",\n",
    "         'formation_energy_per_atom', 'volume']\n",
    "entries = mpr.query(criteria=criteria, properties=props)\n",
    "\n",
    "i = 0\n",
    "for entry in entries:\n",
    "    df.loc[i] = [entry['pretty_formula'], entry['band_gap'], entry['density'],\n",
    "                 entry['formation_energy_per_atom'], entry['volume']]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we try to build the SVR model without using a CBFV it scores poorly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "RNG_SEED = 42\n",
    "np.random.seed(seed=RNG_SEED)\n",
    "\n",
    "X = df[['band_gap','formation_energy_per_atom','volume']]\n",
    "y = df['density']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the found data into train test splits. This is useful for evaluating the model and seeing how accurate it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=RNG_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, lets train the model and score it. We are using the SVR model from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svr = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svr.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('the r2 score is',r2)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('the mean absolute error is',mae)\n",
    "rmse_val = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model isn't too great alone, but what if we add CBFV features? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CBFV import composition\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Rename columns\n",
    "rename_dict = {'density': 'target', 'pretty_formula': 'formula'}\n",
    "df = df.rename(columns=rename_dict)\n",
    "\n",
    "# Fix random seed\n",
    "RNG_SEED = 42\n",
    "np.random.seed(seed=RNG_SEED)\n",
    "\n",
    "# Generate features **before** splitting\n",
    "X, y, formulae, skipped = composition.generate_features(df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "\n",
    "# Drop NaN values or fill missing values\n",
    "X = X.dropna(axis=1, how='all')  # Drops columns with only NaN values\n",
    "imputer = SimpleImputer(strategy=\"mean\")  # Use mean to fill missing values\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=RNG_SEED)\n",
    "\n",
    "# Train SVR model\n",
    "svr = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse_val = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"RÂ² score: {r2}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Root Mean Squared Error: {rmse_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way better! Our R^2 went way up and our MAE went way down\n",
    "\n",
    "# Grid Search Hyperparameter Tuning\n",
    "\n",
    "Now let's try one more time, but this time we'll do hyperparameter tuning! We will continue using the SVR model from sklearn but now we will utilize the sklearn GridSearchCV model to perform hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# Create the SVR model\n",
    "svr = SVR()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the training time\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Train the model with the best parameters\n",
    "svr_best = SVR(**best_params)\n",
    "svr_best.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = svr_best.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"Mean absolute error:\", mae)\n",
    "print(\"Root mean squared error:\", rmse)\n",
    "print(\"Training time:\", training_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random search hyperparameter tuning\n",
    "Now let's try random search hyperparameter tuning. This will use the same strategy as before but with the sklearn RandomizedSearchCV hyperparameter tuning model rather than the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# Create the SVR model\n",
    "svr = SVR()\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=svr, param_distributions=param_grid, cv=5)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the training time\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "# Train the model with the best parameters\n",
    "svr_best = SVR(**best_params)\n",
    "svr_best.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = svr_best.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"Mean absolute error:\", mae)\n",
    "print(\"Root mean squared error:\", rmse)\n",
    "print(\"Training time:\", training_time, \"seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (MaterialsInformatics)",
   "language": "python",
   "name": "materialsinformatics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
