{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading, cleanup and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to a ML project is to obtain the dataset you will be working with. \n",
    "There are many repositories for materials science-specific data (whether online or offline)---consult the accompanying paper for a list of the more commonly used ones.\n",
    "\n",
    "Once you have identified the repository and dataset you will use for your project, you will have to download it to your local machine, or establish a way to reliably access the dataset.\n",
    "Consult the documentation of the repository for how to do this.\n",
    "\n",
    "For this tutorial, we have collected heat capacity ($C_p$) data from the [NIST-JANAF Thermochemical Tables](https://doi.org/10.18434/T42S31)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pkg_resources'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mmatplotlib\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minline\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mInlineBackend.figure_format=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mretina\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\My Drive\\teaching\\5540-6640 Materials Informatics\\MaterialsInformatics\\worked_examples\\best_practices\\.venv\\Lib\\site-packages\\ydata_profiling\\__init__.py:10\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m  \u001b[38;5;66;03m# isort:skip # noqa\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m  \u001b[38;5;66;03m# isort:skip # noqa\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompare_reports\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compare  \u001b[38;5;66;03m# isort:skip # noqa\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontroller\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pandas_decorator  \u001b[38;5;66;03m# isort:skip # noqa\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprofile_report\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport  \u001b[38;5;66;03m# isort:skip # noqa\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\My Drive\\teaching\\5540-6640 Materials Informatics\\MaterialsInformatics\\worked_examples\\best_practices\\.venv\\Lib\\site-packages\\ydata_profiling\\compare_reports.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseDescription\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malerts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Alert\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprofile_report\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_should_wrap\u001b[39m(v1: Any, v2: Any) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v1, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\My Drive\\teaching\\5540-6640 Materials Informatics\\MaterialsInformatics\\worked_examples\\best_practices\\.venv\\Lib\\site-packages\\ydata_profiling\\profile_report.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m warnings.catch_warnings():\n\u001b[32m      8\u001b[39m     warnings.simplefilter(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpkg_resources\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame \u001b[38;5;28;01mas\u001b[39;00m sDataFrame\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pkg_resources'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from ydata_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Using Pandas, we read in the dataset into a DataFrame. \n",
    "\n",
    "We also print the shape of the DataFrame, which indicates the number of rows and columns in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "data_path = os.path.join(PATH, '../data/cp_data_demo.csv')\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(f'Original DataFrame shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that our input dataset has 4583 data samples, each with 3 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the data\n",
    "\n",
    "We examine some rows and look at the data's basic statistics.\n",
    "\n",
    "We see that the dataset contains information about the formula, measurement condition (in this case, temperature in K), and the target property, heat capacity (in J/(mol * K))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing you should notice: we have many observations of the same compound (B2O3) but measured at different measurement conditions, resulting in a different property value.\n",
    "\n",
    "We can get some simple summary statistics of the DataFrame by calling the `.describe()` method on the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There used to be a nice `pandas-profiling` library, but it was replaced by `ydata-profiling` and this has some incompatibilities with our library, so we'll skip this step. If possible, this would be a great tool to include in the future because it is an excellent way to explore data for problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "profile.to_file(\"profile.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice a few things from the profile report:\n",
    "* We have some missing cells in the dataset (\"Overview\" tab)\n",
    "* We have some unrealistic Temperature and Heat Capacity values in the dataset (\"Variables\" tab)\n",
    "* We have some missing Temperature, Formula and Heat Capacity values in the dataset (\"Variables\" tab)\n",
    "\n",
    "Also notice that on the \"Overview\" tab, there is the following warning: `FORMULA` has a high cardinality: 245 distinct values.\n",
    "\n",
    "Cardinality is the number of distinct values in a column of a table, relative to the number of rows in the table.\n",
    "In our dataset, we have a total of 4583 data observations, but only 245 distinct formulae.\n",
    "We will have to keep this in mind later, when we process and split the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename the column names for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {'FORMULA': 'formula',\n",
    "               'CONDITION: Temperature (K)': 'T',\n",
    "               'PROPERTY: Heat Capacity (J/mol K)': 'Cp'}\n",
    "df = df.rename(columns=rename_dict)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for and remove `NaN` values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can use the built-in Pandas methods to check for `NaN` values in the dataset, which are missing values.\n",
    "We then remove the dataset rows which contain `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaNs in the respective dataset columns, and get the indices\n",
    "df2 = df.copy()\n",
    "bool_nans_formula = df2['formula'].isnull()\n",
    "bool_nans_T = df2['T'].isnull()\n",
    "bool_nans_Cp = df2['Cp'].isnull()\n",
    "\n",
    "# Drop the rows of the DataFrame which contain NaNs\n",
    "df2 = df2.drop(df2.loc[bool_nans_formula].index, axis=0)\n",
    "df2 = df2.drop(df2.loc[bool_nans_T].index, axis=0)\n",
    "df2 = df2.drop(df2.loc[bool_nans_Cp].index, axis=0)\n",
    "\n",
    "print(f'DataFrame shape before dropping NaNs: {df.shape}')\n",
    "print(f'DataFrame shape after dropping NaNs: {df2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also includes the convenient built-in method `.dropna()` to check for and remove `NaNs` in-place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()\n",
    "df3 = df3.dropna(axis=0, how='any')\n",
    "\n",
    "print(f'DataFrame shape before dropping NaNs: {df.shape}')\n",
    "print(f'DataFrame shape after dropping NaNs: {df3.shape}')\n",
    "\n",
    "df = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for and remove unrealistic values\n",
    "\n",
    "In some cases, you might also get data values that simply don't make sense.\n",
    "For our dase, this could be negative values in the temperature or heat capacity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_invalid_T = df['T'] < 0\n",
    "bool_invalid_Cp = df['Cp'] < 0\n",
    "\n",
    "df = df.drop(df.loc[bool_invalid_T].index, axis=0)\n",
    "df = df.drop(df.loc[bool_invalid_Cp].index, axis=0)\n",
    "\n",
    "print(f'DataFrame shape after dropping unrealistic values: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for and remove duplicate entries\n",
    "\n",
    "Finally, you should also remove duplicate entries to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "\n",
    "print(f'DataFrame shape after dropping duplicates: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save cleaned data to csv\n",
    "\n",
    "Finally, after cleaning and processing the data, you can save it to disk in a cleaned state for you to use later.\n",
    "\n",
    "Pandas allows us to save our data as a comma separated value `.csv` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(PATH, '../data/cp_data_cleaned.csv')\n",
    "df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, your data can be saved in other file formats (such as hdf5) or in databases (such as SQL), but we will not go into the details of these formats.\n",
    "\n",
    "Typically, the amount of data you can gather for your ML project isn't large enough to warrant these approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "best-practices",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
