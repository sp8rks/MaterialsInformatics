{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sp8rks/MaterialsInformatics/blob/main/worked_examples/hyperparameter_opt/materials_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELFcx4WgrdXV"
      },
      "source": [
        "# Grid vs. Random Search Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrA6ZaIYhd7l"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyPdG8IxhbwG"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tt5zD4rfeavx",
        "outputId": "451fa766-3241-4b77-f7db-bfbe464b98dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting matbench\n",
            "  Downloading matbench-0.5-py3-none-any.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 6.8 MB/s \n",
            "\u001b[?25hCollecting monty==2021.8.17\n",
            "  Downloading monty-2021.8.17-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting matminer==0.7.4\n",
            "  Downloading matminer-0.7.4-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 3.7 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==1.0\n",
            "  Downloading scikit_learn-1.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.1 MB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from matminer==0.7.4->matbench) (4.3.3)\n",
            "Collecting numpy>=1.21.1\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 351 kB/s \n",
            "\u001b[?25hCollecting pint>=0.17\n",
            "  Downloading Pint-0.18-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from matminer==0.7.4->matbench) (1.3.5)\n",
            "Requirement already satisfied: pymongo>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from matminer==0.7.4->matbench) (4.0.1)\n",
            "Collecting requests>=2.26.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting future>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 11.7 MB/s \n",
            "\u001b[?25hCollecting pymatgen>=2022.0.11\n",
            "  Downloading pymatgen-2022.0.17.tar.gz (40.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 40.6 MB 17.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.7/dist-packages (from matminer==0.7.4->matbench) (4.62.3)\n",
            "Collecting sympy>=1.8\n",
            "  Downloading sympy-1.9-py3-none-any.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 19.9 MB/s \n",
            "\u001b[?25hCollecting six>=1.16.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0->matbench) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0->matbench) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0->matbench) (1.4.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->matminer==0.7.4->matbench) (0.18.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->matminer==0.7.4->matbench) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->matminer==0.7.4->matbench) (4.10.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->matminer==0.7.4->matbench) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->matminer==0.7.4->matbench) (5.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.2.0->matminer==0.7.4->matbench) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.3.1->matminer==0.7.4->matbench) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.3.1->matminer==0.7.4->matbench) (2018.9)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pint>=0.17->matminer==0.7.4->matbench) (21.3)\n",
            "Collecting scipy>=1.1.0\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting spglib>=1.9.9.44\n",
            "  Downloading spglib-1.16.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
            "\u001b[K     |████████████████████████████████| 292 kB 73.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly>=4.5.0 in /usr/local/lib/python3.7/dist-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (5.5.0)\n",
            "Collecting ruamel.yaml>=0.15.6\n",
            "  Downloading ruamel.yaml-0.17.20-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 71.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (0.8.9)\n",
            "Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.7/dist-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (3.2.2)\n",
            "Collecting uncertainties>=3.1.4\n",
            "  Downloading uncertainties-3.1.6-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 10.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: palettable>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (3.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from pymatgen>=2022.0.11->matminer==0.7.4->matbench) (2.6.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen>=2022.0.11->matminer==0.7.4->matbench) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen>=2022.0.11->matminer==0.7.4->matbench) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen>=2022.0.11->matminer==0.7.4->matbench) (0.11.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.5.0->pymatgen>=2022.0.11->matminer==0.7.4->matbench) (8.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->matminer==0.7.4->matbench) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->matminer==0.7.4->matbench) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->matminer==0.7.4->matbench) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->matminer==0.7.4->matbench) (2.0.11)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.8->matminer==0.7.4->matbench) (1.2.1)\n",
            "Building wheels for collected packages: future, pymatgen\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=70bfaeee11de79774a7c0e8aed771e75fb6d7ad171358d66633ff558687e7bd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for pymatgen (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymatgen: filename=pymatgen-2022.0.17-cp37-cp37m-linux_x86_64.whl size=41841005 sha256=e47f41b2c33b4e17d06ebd93d56ae0085228489168cc4f6c725decd79b788271\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/f6/22/58a9be23c5f1b452770e02ff42047175eaf0f9c2f15219fc76\n",
            "Successfully built future pymatgen\n",
            "Installing collected packages: six, ruamel.yaml.clib, numpy, future, uncertainties, sympy, spglib, scipy, ruamel.yaml, requests, monty, scikit-learn, pymatgen, pint, matminer, matbench\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.7.1\n",
            "    Uninstalling sympy-1.7.1:\n",
            "      Successfully uninstalled sympy-1.7.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed future-0.18.2 matbench-0.5 matminer-0.7.4 monty-2021.8.17 numpy-1.21.5 pint-0.18 pymatgen-2022.0.17 requests-2.27.1 ruamel.yaml-0.17.20 ruamel.yaml.clib-0.2.6 scikit-learn-1.0 scipy-1.7.3 six-1.16.0 spglib-1.16.3 sympy-1.9 uncertainties-3.1.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting CBFV\n",
            "  Downloading CBFV-1.1.0-py3-none-any.whl (539 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 102 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 112 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 133 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 153 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 204 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 225 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 245 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 266 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 296 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 307 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 317 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 327 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 358 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 378 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 399 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 409 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 419 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 430 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 440 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 450 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 460 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 471 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 481 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 491 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 501 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 512 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 522 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 532 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 539 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from CBFV) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from CBFV) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from CBFV) (1.21.5)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from CBFV) (3.6.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->CBFV) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->CBFV) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->CBFV) (1.16.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->CBFV) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->CBFV) (21.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->CBFV) (1.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->CBFV) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->CBFV) (8.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->CBFV) (57.4.0)\n",
            "Installing collected packages: CBFV\n",
            "Successfully installed CBFV-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install matbench\n",
        "!pip install CBFV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVTbZicohiDd"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yXjOg8s6ehcm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from scipy.stats import randint\n",
        "\n",
        "from matbench.bench import MatbenchBenchmark\n",
        "from CBFV.composition import generate_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT51Iu3zhjJ8"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7hygIC8fGb9",
        "outputId": "98d10ff3-7c3f-4e1d-a1b2-4aa727ae9562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-09 21:36:57 INFO     Initialized benchmark 'matbench_v0.1' with 1 tasks: \n",
            "['matbench_expt_is_metal']\n",
            "2022-02-09 21:36:57 INFO     Loading dataset 'matbench_expt_is_metal'...\n",
            "Fetching matbench_expt_is_metal.json.gz from https://ml.materialsproject.org/projects/matbench_expt_is_metal.json.gz to /usr/local/lib/python3.7/dist-packages/matminer/datasets/matbench_expt_is_metal.json.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching https://ml.materialsproject.org/projects/matbench_expt_is_metal.json.gz in MB: 0.034816MB [00:00, 40.50MB/s]                 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-09 21:36:57 INFO     Dataset 'matbench_expt_is_metal loaded.\n",
            "mbid\n",
            "mb-expt-is-metal-0001      Ag(AuS)2\n",
            "mb-expt-is-metal-0002    Ag(W3Br7)2\n",
            "Name: composition, dtype: object mbid\n",
            "mb-expt-is-metal-0001    True\n",
            "mb-expt-is-metal-0002    True\n",
            "Name: is_metal, dtype: bool\n",
            "(3936,) (985,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "mb = MatbenchBenchmark(subset=[\"matbench_expt_is_metal\"])\n",
        "task = list(mb.tasks)[0]\n",
        "task.load()\n",
        "fold0 = task.folds[0]\n",
        "train_inputs, train_outputs = task.get_train_and_val_data(fold0)\n",
        "test_inputs, test_outputs = task.get_test_data(fold0, include_target=True)\n",
        "print(train_inputs[0:2], train_outputs[0:2])\n",
        "print(train_outputs.shape, test_outputs.shape)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V5GF1n6gw6V",
        "outputId": "6b1af8ec-9c01-4644-de20-14b86f84a3ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count         3936\n",
              "unique        3936\n",
              "top       Ag(AuS)2\n",
              "freq             1\n",
              "Name: composition, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_inputs.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ldpId5_gaNO",
        "outputId": "70168c23-bb5b-486a-8659-0e255f68f0d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count      3936\n",
              "unique        2\n",
              "top       False\n",
              "freq       1976\n",
              "Name: is_metal, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_outputs.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "bj2GVnAmgoz2",
        "outputId": "734cbf72-cf59-4a40-fab9-a195f499e3c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0205870f-7206-490c-adab-8ca7336460cb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>formula</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mbid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mb-expt-is-metal-0001</th>\n",
              "      <td>Ag(AuS)2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mb-expt-is-metal-0002</th>\n",
              "      <td>Ag(W3Br7)2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mb-expt-is-metal-0003</th>\n",
              "      <td>Ag0.5Ge1Pb1.75S4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mb-expt-is-metal-0005</th>\n",
              "      <td>Ag2BBr</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mb-expt-is-metal-0006</th>\n",
              "      <td>Ag2BiO3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mb-expt-is-metal-4916</th>\n",
              "      <td>ZrSiTe</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mb-expt-is-metal-4917</th>\n",
              "      <td>ZrTaN3</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mb-expt-is-metal-4918</th>\n",
              "      <td>ZrTe</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mb-expt-is-metal-4920</th>\n",
              "      <td>ZrTiF6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mb-expt-is-metal-4921</th>\n",
              "      <td>ZrW2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3936 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0205870f-7206-490c-adab-8ca7336460cb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0205870f-7206-490c-adab-8ca7336460cb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0205870f-7206-490c-adab-8ca7336460cb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                formula  target\n",
              "mbid                                           \n",
              "mb-expt-is-metal-0001          Ag(AuS)2    True\n",
              "mb-expt-is-metal-0002        Ag(W3Br7)2    True\n",
              "mb-expt-is-metal-0003  Ag0.5Ge1Pb1.75S4   False\n",
              "mb-expt-is-metal-0005            Ag2BBr    True\n",
              "mb-expt-is-metal-0006           Ag2BiO3    True\n",
              "...                                 ...     ...\n",
              "mb-expt-is-metal-4916            ZrSiTe    True\n",
              "mb-expt-is-metal-4917            ZrTaN3   False\n",
              "mb-expt-is-metal-4918              ZrTe    True\n",
              "mb-expt-is-metal-4920            ZrTiF6    True\n",
              "mb-expt-is-metal-4921              ZrW2    True\n",
              "\n",
              "[3936 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_df = pd.DataFrame({\"formula\": train_inputs, \"target\": train_outputs})\n",
        "test_df = pd.DataFrame({\"formula\": test_inputs, \"target\": test_outputs})\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "8K6r-swAhGq9",
        "outputId": "70576fe3-018c-410c-a5e2-d75dfc319910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Input Data: 100%|██████████| 3936/3936 [00:00<00:00, 15165.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tFeaturizing Compositions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Assigning Features...: 100%|██████████| 3936/3936 [00:00<00:00, 8136.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tCreating Pandas Objects...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d37b331d-cba9-4354-a54e-2aa92c52f0f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_Atomic_Number</th>\n",
              "      <th>avg_Atomic_Weight</th>\n",
              "      <th>avg_Period</th>\n",
              "      <th>avg_group</th>\n",
              "      <th>avg_families</th>\n",
              "      <th>avg_Metal</th>\n",
              "      <th>avg_Nonmetal</th>\n",
              "      <th>avg_Metalliod</th>\n",
              "      <th>avg_Mendeleev_Number</th>\n",
              "      <th>avg_l_quantum_number</th>\n",
              "      <th>avg_Atomic_Radius</th>\n",
              "      <th>avg_Miracle_Radius_[pm]</th>\n",
              "      <th>avg_Covalent_Radius</th>\n",
              "      <th>avg_Zunger_radii_sum</th>\n",
              "      <th>avg_ionic_radius</th>\n",
              "      <th>avg_crystal_radius</th>\n",
              "      <th>avg_Pauling_Electronegativity</th>\n",
              "      <th>avg_MB_electonegativity</th>\n",
              "      <th>avg_Gordy_electonegativity</th>\n",
              "      <th>avg_Mulliken_EN</th>\n",
              "      <th>avg_Allred-Rockow_electronegativity</th>\n",
              "      <th>avg_metallic_valence</th>\n",
              "      <th>avg_number_of_valence_electrons</th>\n",
              "      <th>avg_gilmor_number_of_valence_electron</th>\n",
              "      <th>avg_valence_s</th>\n",
              "      <th>avg_valence_p</th>\n",
              "      <th>avg_valence_d</th>\n",
              "      <th>avg_valence_f</th>\n",
              "      <th>avg_Number_of_unfilled_s_valence_electrons</th>\n",
              "      <th>avg_Number_of_unfilled_p_valence_electrons</th>\n",
              "      <th>avg_Number_of_unfilled_d_valence_electrons</th>\n",
              "      <th>avg_Number_of_unfilled_f_valence_electrons</th>\n",
              "      <th>avg_outer_shell_electrons</th>\n",
              "      <th>avg_1st_ionization_potential_(kJ/mol)</th>\n",
              "      <th>avg_polarizability(A^3)</th>\n",
              "      <th>avg_Melting_point_(K)</th>\n",
              "      <th>avg_Boiling_Point_(K)</th>\n",
              "      <th>avg_Density_(g/mL)</th>\n",
              "      <th>avg_specific_heat_(J/g_K)_</th>\n",
              "      <th>avg_heat_of_fusion_(kJ/mol)_</th>\n",
              "      <th>...</th>\n",
              "      <th>mode_families</th>\n",
              "      <th>mode_Metal</th>\n",
              "      <th>mode_Nonmetal</th>\n",
              "      <th>mode_Metalliod</th>\n",
              "      <th>mode_Mendeleev_Number</th>\n",
              "      <th>mode_l_quantum_number</th>\n",
              "      <th>mode_Atomic_Radius</th>\n",
              "      <th>mode_Miracle_Radius_[pm]</th>\n",
              "      <th>mode_Covalent_Radius</th>\n",
              "      <th>mode_Zunger_radii_sum</th>\n",
              "      <th>mode_ionic_radius</th>\n",
              "      <th>mode_crystal_radius</th>\n",
              "      <th>mode_Pauling_Electronegativity</th>\n",
              "      <th>mode_MB_electonegativity</th>\n",
              "      <th>mode_Gordy_electonegativity</th>\n",
              "      <th>mode_Mulliken_EN</th>\n",
              "      <th>mode_Allred-Rockow_electronegativity</th>\n",
              "      <th>mode_metallic_valence</th>\n",
              "      <th>mode_number_of_valence_electrons</th>\n",
              "      <th>mode_gilmor_number_of_valence_electron</th>\n",
              "      <th>mode_valence_s</th>\n",
              "      <th>mode_valence_p</th>\n",
              "      <th>mode_valence_d</th>\n",
              "      <th>mode_valence_f</th>\n",
              "      <th>mode_Number_of_unfilled_s_valence_electrons</th>\n",
              "      <th>mode_Number_of_unfilled_p_valence_electrons</th>\n",
              "      <th>mode_Number_of_unfilled_d_valence_electrons</th>\n",
              "      <th>mode_Number_of_unfilled_f_valence_electrons</th>\n",
              "      <th>mode_outer_shell_electrons</th>\n",
              "      <th>mode_1st_ionization_potential_(kJ/mol)</th>\n",
              "      <th>mode_polarizability(A^3)</th>\n",
              "      <th>mode_Melting_point_(K)</th>\n",
              "      <th>mode_Boiling_Point_(K)</th>\n",
              "      <th>mode_Density_(g/mL)</th>\n",
              "      <th>mode_specific_heat_(J/g_K)_</th>\n",
              "      <th>mode_heat_of_fusion_(kJ/mol)_</th>\n",
              "      <th>mode_heat_of_vaporization_(kJ/mol)_</th>\n",
              "      <th>mode_thermal_conductivity_(W/(m_K))_</th>\n",
              "      <th>mode_heat_atomization(kJ/mol)</th>\n",
              "      <th>mode_Cohesive_energy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>47.400000</td>\n",
              "      <td>113.186656</td>\n",
              "      <td>4.600000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>74.600000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>1.378000</td>\n",
              "      <td>127.200000</td>\n",
              "      <td>1.290000</td>\n",
              "      <td>1.979000</td>\n",
              "      <td>1.260000</td>\n",
              "      <td>1.034000</td>\n",
              "      <td>2.434000</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>6.300400</td>\n",
              "      <td>5.684000</td>\n",
              "      <td>2.177600</td>\n",
              "      <td>4.064000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>902.200000</td>\n",
              "      <td>5.180000</td>\n",
              "      <td>936.270000</td>\n",
              "      <td>2125.430000</td>\n",
              "      <td>10.648000</td>\n",
              "      <td>0.382200</td>\n",
              "      <td>7.967000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.88</td>\n",
              "      <td>103.0</td>\n",
              "      <td>1.02</td>\n",
              "      <td>1.100</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.43</td>\n",
              "      <td>2.54</td>\n",
              "      <td>1.19</td>\n",
              "      <td>5.8458</td>\n",
              "      <td>5.77</td>\n",
              "      <td>1.920</td>\n",
              "      <td>2.00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>890.0</td>\n",
              "      <td>2.900</td>\n",
              "      <td>385.95</td>\n",
              "      <td>717.85</td>\n",
              "      <td>2.07000</td>\n",
              "      <td>0.128</td>\n",
              "      <td>1.71750</td>\n",
              "      <td>9.8000</td>\n",
              "      <td>0.26900</td>\n",
              "      <td>279.0</td>\n",
              "      <td>2.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46.714286</td>\n",
              "      <td>110.931629</td>\n",
              "      <td>4.619048</td>\n",
              "      <td>13.571429</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.238095</td>\n",
              "      <td>1.256667</td>\n",
              "      <td>133.242647</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.694524</td>\n",
              "      <td>1.228571</td>\n",
              "      <td>1.486190</td>\n",
              "      <td>2.739524</td>\n",
              "      <td>2.449048</td>\n",
              "      <td>6.393686</td>\n",
              "      <td>6.528571</td>\n",
              "      <td>2.299048</td>\n",
              "      <td>1.910476</td>\n",
              "      <td>6.904762</td>\n",
              "      <td>5.904762</td>\n",
              "      <td>1.952381</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>1.619048</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>8.380952</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.285714</td>\n",
              "      <td>1014.809524</td>\n",
              "      <td>5.614286</td>\n",
              "      <td>1288.445238</td>\n",
              "      <td>2034.826190</td>\n",
              "      <td>8.094286</td>\n",
              "      <td>0.363667</td>\n",
              "      <td>14.176381</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.94</td>\n",
              "      <td>115.0</td>\n",
              "      <td>1.14</td>\n",
              "      <td>1.200</td>\n",
              "      <td>1.15</td>\n",
              "      <td>1.82</td>\n",
              "      <td>2.96</td>\n",
              "      <td>2.83</td>\n",
              "      <td>6.4079</td>\n",
              "      <td>7.59</td>\n",
              "      <td>2.685</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1140.0</td>\n",
              "      <td>3.100</td>\n",
              "      <td>265.95</td>\n",
              "      <td>331.95</td>\n",
              "      <td>3.12000</td>\n",
              "      <td>0.473</td>\n",
              "      <td>5.28600</td>\n",
              "      <td>15.4380</td>\n",
              "      <td>0.12200</td>\n",
              "      <td>112.0</td>\n",
              "      <td>1.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36.275862</td>\n",
              "      <td>85.159738</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>14.896552</td>\n",
              "      <td>6.172414</td>\n",
              "      <td>0.310345</td>\n",
              "      <td>0.551724</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>83.482759</td>\n",
              "      <td>0.931034</td>\n",
              "      <td>1.143448</td>\n",
              "      <td>124.482759</td>\n",
              "      <td>1.191379</td>\n",
              "      <td>1.490345</td>\n",
              "      <td>1.268966</td>\n",
              "      <td>0.758966</td>\n",
              "      <td>2.285172</td>\n",
              "      <td>2.273793</td>\n",
              "      <td>5.275255</td>\n",
              "      <td>5.313793</td>\n",
              "      <td>2.279931</td>\n",
              "      <td>2.619310</td>\n",
              "      <td>5.586207</td>\n",
              "      <td>4.965517</td>\n",
              "      <td>1.931034</td>\n",
              "      <td>2.965517</td>\n",
              "      <td>3.103448</td>\n",
              "      <td>3.379310</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>3.034483</td>\n",
              "      <td>6.896552</td>\n",
              "      <td>10.620690</td>\n",
              "      <td>4.896552</td>\n",
              "      <td>880.068966</td>\n",
              "      <td>4.627586</td>\n",
              "      <td>611.456897</td>\n",
              "      <td>1481.398276</td>\n",
              "      <td>5.351724</td>\n",
              "      <td>0.483448</td>\n",
              "      <td>7.980448</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.88</td>\n",
              "      <td>103.0</td>\n",
              "      <td>1.02</td>\n",
              "      <td>1.100</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.43</td>\n",
              "      <td>2.58</td>\n",
              "      <td>2.65</td>\n",
              "      <td>5.8458</td>\n",
              "      <td>6.22</td>\n",
              "      <td>2.589</td>\n",
              "      <td>2.00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>2.900</td>\n",
              "      <td>385.95</td>\n",
              "      <td>717.85</td>\n",
              "      <td>2.07000</td>\n",
              "      <td>0.710</td>\n",
              "      <td>1.71750</td>\n",
              "      <td>9.8000</td>\n",
              "      <td>0.26900</td>\n",
              "      <td>279.0</td>\n",
              "      <td>2.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33.500000</td>\n",
              "      <td>76.612850</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>74.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.277500</td>\n",
              "      <td>133.242647</td>\n",
              "      <td>1.255000</td>\n",
              "      <td>1.686250</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>1.162500</td>\n",
              "      <td>2.215000</td>\n",
              "      <td>1.717500</td>\n",
              "      <td>4.676850</td>\n",
              "      <td>5.190000</td>\n",
              "      <td>2.119000</td>\n",
              "      <td>3.470000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>850.750000</td>\n",
              "      <td>5.475000</td>\n",
              "      <td>1272.100000</td>\n",
              "      <td>2394.312500</td>\n",
              "      <td>6.615000</td>\n",
              "      <td>0.490750</td>\n",
              "      <td>19.521500</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>144.0</td>\n",
              "      <td>1.53</td>\n",
              "      <td>2.375</td>\n",
              "      <td>1.60</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>1.07</td>\n",
              "      <td>3.8522</td>\n",
              "      <td>4.44</td>\n",
              "      <td>1.870</td>\n",
              "      <td>5.44</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>731.0</td>\n",
              "      <td>7.900</td>\n",
              "      <td>1235.15</td>\n",
              "      <td>2485.15</td>\n",
              "      <td>10.50000</td>\n",
              "      <td>0.235</td>\n",
              "      <td>11.30000</td>\n",
              "      <td>250.5800</td>\n",
              "      <td>429.00000</td>\n",
              "      <td>284.0</td>\n",
              "      <td>2.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33.500000</td>\n",
              "      <td>78.785828</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>14.166667</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.028333</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>1.118333</td>\n",
              "      <td>1.357000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>1.230000</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>2.373333</td>\n",
              "      <td>6.274017</td>\n",
              "      <td>6.031667</td>\n",
              "      <td>2.763333</td>\n",
              "      <td>2.313333</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>11.666667</td>\n",
              "      <td>4.166667</td>\n",
              "      <td>1017.833333</td>\n",
              "      <td>4.263167</td>\n",
              "      <td>529.783333</td>\n",
              "      <td>1178.983333</td>\n",
              "      <td>5.125715</td>\n",
              "      <td>0.558333</td>\n",
              "      <td>5.761295</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.48</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.21</td>\n",
              "      <td>3.44</td>\n",
              "      <td>3.32</td>\n",
              "      <td>8.3703</td>\n",
              "      <td>7.54</td>\n",
              "      <td>3.610</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1314.0</td>\n",
              "      <td>0.793</td>\n",
              "      <td>54.75</td>\n",
              "      <td>90.15</td>\n",
              "      <td>0.00143</td>\n",
              "      <td>0.920</td>\n",
              "      <td>0.22259</td>\n",
              "      <td>3.4099</td>\n",
              "      <td>0.02674</td>\n",
              "      <td>249.0</td>\n",
              "      <td>2.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3931</th>\n",
              "      <td>35.333333</td>\n",
              "      <td>82.303167</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>11.333333</td>\n",
              "      <td>5.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.666667</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.466667</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>1.313333</td>\n",
              "      <td>1.971667</td>\n",
              "      <td>1.350000</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>1.776667</td>\n",
              "      <td>2.020000</td>\n",
              "      <td>4.359700</td>\n",
              "      <td>4.633333</td>\n",
              "      <td>1.798000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>765.333333</td>\n",
              "      <td>9.600000</td>\n",
              "      <td>1510.316667</td>\n",
              "      <td>2847.083333</td>\n",
              "      <td>5.026667</td>\n",
              "      <td>0.393333</td>\n",
              "      <td>28.313333</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.11</td>\n",
              "      <td>110.0</td>\n",
              "      <td>1.11</td>\n",
              "      <td>1.420</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.33</td>\n",
              "      <td>1.70</td>\n",
              "      <td>3.4521</td>\n",
              "      <td>3.64</td>\n",
              "      <td>1.320</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>640.0</td>\n",
              "      <td>5.400</td>\n",
              "      <td>722.65</td>\n",
              "      <td>1262.95</td>\n",
              "      <td>2.33000</td>\n",
              "      <td>0.200</td>\n",
              "      <td>16.90000</td>\n",
              "      <td>52.5500</td>\n",
              "      <td>2.35000</td>\n",
              "      <td>197.0</td>\n",
              "      <td>2.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3932</th>\n",
              "      <td>26.800000</td>\n",
              "      <td>62.838424</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>67.600000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>1.148000</td>\n",
              "      <td>103.800000</td>\n",
              "      <td>1.022000</td>\n",
              "      <td>1.447000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.508000</td>\n",
              "      <td>2.390000</td>\n",
              "      <td>2.438000</td>\n",
              "      <td>6.135220</td>\n",
              "      <td>5.930000</td>\n",
              "      <td>2.371600</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>1121.400000</td>\n",
              "      <td>6.860000</td>\n",
              "      <td>1116.810000</td>\n",
              "      <td>2116.070000</td>\n",
              "      <td>4.622750</td>\n",
              "      <td>0.706000</td>\n",
              "      <td>9.916240</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.56</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.30</td>\n",
              "      <td>3.04</td>\n",
              "      <td>2.85</td>\n",
              "      <td>6.8834</td>\n",
              "      <td>7.30</td>\n",
              "      <td>3.066</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1402.0</td>\n",
              "      <td>1.100</td>\n",
              "      <td>63.25</td>\n",
              "      <td>77.35</td>\n",
              "      <td>0.00125</td>\n",
              "      <td>1.040</td>\n",
              "      <td>0.36040</td>\n",
              "      <td>2.7928</td>\n",
              "      <td>0.02598</td>\n",
              "      <td>473.0</td>\n",
              "      <td>4.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3933</th>\n",
              "      <td>46.000000</td>\n",
              "      <td>109.412000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.645000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>1.415000</td>\n",
              "      <td>2.247500</td>\n",
              "      <td>1.475000</td>\n",
              "      <td>0.985000</td>\n",
              "      <td>1.715000</td>\n",
              "      <td>2.040000</td>\n",
              "      <td>4.446950</td>\n",
              "      <td>4.565000</td>\n",
              "      <td>1.739000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>754.500000</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>1423.900000</td>\n",
              "      <td>2956.550000</td>\n",
              "      <td>6.375000</td>\n",
              "      <td>0.235000</td>\n",
              "      <td>17.195000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>140.0</td>\n",
              "      <td>1.35</td>\n",
              "      <td>1.670</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.33</td>\n",
              "      <td>1.70</td>\n",
              "      <td>3.4521</td>\n",
              "      <td>3.64</td>\n",
              "      <td>1.320</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>640.0</td>\n",
              "      <td>5.500</td>\n",
              "      <td>722.65</td>\n",
              "      <td>1262.95</td>\n",
              "      <td>6.24000</td>\n",
              "      <td>0.200</td>\n",
              "      <td>16.90000</td>\n",
              "      <td>52.5500</td>\n",
              "      <td>2.35000</td>\n",
              "      <td>197.0</td>\n",
              "      <td>2.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3934</th>\n",
              "      <td>14.500000</td>\n",
              "      <td>31.636802</td>\n",
              "      <td>2.625000</td>\n",
              "      <td>13.750000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.625000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.792500</td>\n",
              "      <td>133.242647</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.979375</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>1.093750</td>\n",
              "      <td>3.343750</td>\n",
              "      <td>3.280000</td>\n",
              "      <td>8.387550</td>\n",
              "      <td>8.693750</td>\n",
              "      <td>3.482250</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>5.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>5.750000</td>\n",
              "      <td>1423.125000</td>\n",
              "      <td>4.538000</td>\n",
              "      <td>547.300000</td>\n",
              "      <td>1090.075000</td>\n",
              "      <td>1.382525</td>\n",
              "      <td>0.713750</td>\n",
              "      <td>4.235150</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.42</td>\n",
              "      <td>115.0</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.405</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.19</td>\n",
              "      <td>3.98</td>\n",
              "      <td>3.78</td>\n",
              "      <td>10.0854</td>\n",
              "      <td>10.41</td>\n",
              "      <td>4.193</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1681.0</td>\n",
              "      <td>0.634</td>\n",
              "      <td>53.35</td>\n",
              "      <td>85.05</td>\n",
              "      <td>0.00170</td>\n",
              "      <td>0.820</td>\n",
              "      <td>0.25520</td>\n",
              "      <td>3.2698</td>\n",
              "      <td>0.02790</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3935</th>\n",
              "      <td>62.666667</td>\n",
              "      <td>152.968000</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>5.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.666667</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.973333</td>\n",
              "      <td>142.666667</td>\n",
              "      <td>1.466667</td>\n",
              "      <td>2.765000</td>\n",
              "      <td>1.416667</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>2.016667</td>\n",
              "      <td>1.760000</td>\n",
              "      <td>5.673433</td>\n",
              "      <td>4.146667</td>\n",
              "      <td>1.420000</td>\n",
              "      <td>5.186667</td>\n",
              "      <td>5.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>9.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>726.666667</td>\n",
              "      <td>13.366667</td>\n",
              "      <td>3163.816667</td>\n",
              "      <td>5505.483333</td>\n",
              "      <td>15.036667</td>\n",
              "      <td>0.176667</td>\n",
              "      <td>29.233333</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.93</td>\n",
              "      <td>135.0</td>\n",
              "      <td>1.46</td>\n",
              "      <td>2.735</td>\n",
              "      <td>1.35</td>\n",
              "      <td>0.74</td>\n",
              "      <td>2.36</td>\n",
              "      <td>1.79</td>\n",
              "      <td>6.7841</td>\n",
              "      <td>4.40</td>\n",
              "      <td>1.470</td>\n",
              "      <td>5.78</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>770.0</td>\n",
              "      <td>11.100</td>\n",
              "      <td>3683.15</td>\n",
              "      <td>5933.15</td>\n",
              "      <td>19.30000</td>\n",
              "      <td>0.130</td>\n",
              "      <td>35.40000</td>\n",
              "      <td>824.0000</td>\n",
              "      <td>174.00000</td>\n",
              "      <td>849.0</td>\n",
              "      <td>8.90</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3936 rows × 264 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d37b331d-cba9-4354-a54e-2aa92c52f0f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d37b331d-cba9-4354-a54e-2aa92c52f0f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d37b331d-cba9-4354-a54e-2aa92c52f0f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      avg_Atomic_Number  ...  mode_Cohesive_energy\n",
              "0             47.400000  ...                  2.85\n",
              "1             46.714286  ...                  1.22\n",
              "2             36.275862  ...                  2.85\n",
              "3             33.500000  ...                  2.95\n",
              "4             33.500000  ...                  2.62\n",
              "...                 ...  ...                   ...\n",
              "3931          35.333333  ...                  2.19\n",
              "3932          26.800000  ...                  4.92\n",
              "3933          46.000000  ...                  2.19\n",
              "3934          14.500000  ...                  0.84\n",
              "3935          62.666667  ...                  8.90\n",
              "\n",
              "[3936 rows x 264 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X_train, y_train, _, _ = generate_features(train_df)\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "9_RtynXIhL2e",
        "outputId": "55a2d218-54ed-4fe9-ef73-7a9fc5a9ea38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Input Data: 100%|██████████| 985/985 [00:00<00:00, 15770.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tFeaturizing Compositions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Assigning Features...: 100%|██████████| 985/985 [00:00<00:00, 7830.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tCreating Pandas Objects...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-47df7bdd-c8f9-4c54-8da3-864c081af92c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_Atomic_Number</th>\n",
              "      <th>avg_Atomic_Weight</th>\n",
              "      <th>avg_Period</th>\n",
              "      <th>avg_group</th>\n",
              "      <th>avg_families</th>\n",
              "      <th>avg_Metal</th>\n",
              "      <th>avg_Nonmetal</th>\n",
              "      <th>avg_Metalliod</th>\n",
              "      <th>avg_Mendeleev_Number</th>\n",
              "      <th>avg_l_quantum_number</th>\n",
              "      <th>avg_Atomic_Radius</th>\n",
              "      <th>avg_Miracle_Radius_[pm]</th>\n",
              "      <th>avg_Covalent_Radius</th>\n",
              "      <th>avg_Zunger_radii_sum</th>\n",
              "      <th>avg_ionic_radius</th>\n",
              "      <th>avg_crystal_radius</th>\n",
              "      <th>avg_Pauling_Electronegativity</th>\n",
              "      <th>avg_MB_electonegativity</th>\n",
              "      <th>avg_Gordy_electonegativity</th>\n",
              "      <th>avg_Mulliken_EN</th>\n",
              "      <th>avg_Allred-Rockow_electronegativity</th>\n",
              "      <th>avg_metallic_valence</th>\n",
              "      <th>avg_number_of_valence_electrons</th>\n",
              "      <th>avg_gilmor_number_of_valence_electron</th>\n",
              "      <th>avg_valence_s</th>\n",
              "      <th>avg_valence_p</th>\n",
              "      <th>avg_valence_d</th>\n",
              "      <th>avg_valence_f</th>\n",
              "      <th>avg_Number_of_unfilled_s_valence_electrons</th>\n",
              "      <th>avg_Number_of_unfilled_p_valence_electrons</th>\n",
              "      <th>avg_Number_of_unfilled_d_valence_electrons</th>\n",
              "      <th>avg_Number_of_unfilled_f_valence_electrons</th>\n",
              "      <th>avg_outer_shell_electrons</th>\n",
              "      <th>avg_1st_ionization_potential_(kJ/mol)</th>\n",
              "      <th>avg_polarizability(A^3)</th>\n",
              "      <th>avg_Melting_point_(K)</th>\n",
              "      <th>avg_Boiling_Point_(K)</th>\n",
              "      <th>avg_Density_(g/mL)</th>\n",
              "      <th>avg_specific_heat_(J/g_K)_</th>\n",
              "      <th>avg_heat_of_fusion_(kJ/mol)_</th>\n",
              "      <th>...</th>\n",
              "      <th>mode_families</th>\n",
              "      <th>mode_Metal</th>\n",
              "      <th>mode_Nonmetal</th>\n",
              "      <th>mode_Metalliod</th>\n",
              "      <th>mode_Mendeleev_Number</th>\n",
              "      <th>mode_l_quantum_number</th>\n",
              "      <th>mode_Atomic_Radius</th>\n",
              "      <th>mode_Miracle_Radius_[pm]</th>\n",
              "      <th>mode_Covalent_Radius</th>\n",
              "      <th>mode_Zunger_radii_sum</th>\n",
              "      <th>mode_ionic_radius</th>\n",
              "      <th>mode_crystal_radius</th>\n",
              "      <th>mode_Pauling_Electronegativity</th>\n",
              "      <th>mode_MB_electonegativity</th>\n",
              "      <th>mode_Gordy_electonegativity</th>\n",
              "      <th>mode_Mulliken_EN</th>\n",
              "      <th>mode_Allred-Rockow_electronegativity</th>\n",
              "      <th>mode_metallic_valence</th>\n",
              "      <th>mode_number_of_valence_electrons</th>\n",
              "      <th>mode_gilmor_number_of_valence_electron</th>\n",
              "      <th>mode_valence_s</th>\n",
              "      <th>mode_valence_p</th>\n",
              "      <th>mode_valence_d</th>\n",
              "      <th>mode_valence_f</th>\n",
              "      <th>mode_Number_of_unfilled_s_valence_electrons</th>\n",
              "      <th>mode_Number_of_unfilled_p_valence_electrons</th>\n",
              "      <th>mode_Number_of_unfilled_d_valence_electrons</th>\n",
              "      <th>mode_Number_of_unfilled_f_valence_electrons</th>\n",
              "      <th>mode_outer_shell_electrons</th>\n",
              "      <th>mode_1st_ionization_potential_(kJ/mol)</th>\n",
              "      <th>mode_polarizability(A^3)</th>\n",
              "      <th>mode_Melting_point_(K)</th>\n",
              "      <th>mode_Boiling_Point_(K)</th>\n",
              "      <th>mode_Density_(g/mL)</th>\n",
              "      <th>mode_specific_heat_(J/g_K)_</th>\n",
              "      <th>mode_heat_of_fusion_(kJ/mol)_</th>\n",
              "      <th>mode_heat_of_vaporization_(kJ/mol)_</th>\n",
              "      <th>mode_thermal_conductivity_(W/(m_K))_</th>\n",
              "      <th>mode_heat_atomization(kJ/mol)</th>\n",
              "      <th>mode_Cohesive_energy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>46.206897</td>\n",
              "      <td>111.032290</td>\n",
              "      <td>4.551724</td>\n",
              "      <td>14.896552</td>\n",
              "      <td>6.172414</td>\n",
              "      <td>0.310345</td>\n",
              "      <td>0.551724</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>84.034483</td>\n",
              "      <td>0.931034</td>\n",
              "      <td>1.226207</td>\n",
              "      <td>132.758621</td>\n",
              "      <td>1.268621</td>\n",
              "      <td>1.592414</td>\n",
              "      <td>1.351724</td>\n",
              "      <td>0.830690</td>\n",
              "      <td>2.268621</td>\n",
              "      <td>2.213103</td>\n",
              "      <td>5.228469</td>\n",
              "      <td>5.131724</td>\n",
              "      <td>2.194414</td>\n",
              "      <td>2.619310</td>\n",
              "      <td>5.586207</td>\n",
              "      <td>4.965517</td>\n",
              "      <td>1.931034</td>\n",
              "      <td>2.965517</td>\n",
              "      <td>3.103448</td>\n",
              "      <td>3.37931</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>3.034483</td>\n",
              "      <td>6.896552</td>\n",
              "      <td>10.62069</td>\n",
              "      <td>4.896552</td>\n",
              "      <td>847.517241</td>\n",
              "      <td>5.124138</td>\n",
              "      <td>668.946552</td>\n",
              "      <td>1613.977586</td>\n",
              "      <td>6.852414</td>\n",
              "      <td>0.268276</td>\n",
              "      <td>10.726103</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.03</td>\n",
              "      <td>118.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>1.285</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.56</td>\n",
              "      <td>2.55</td>\n",
              "      <td>2.54</td>\n",
              "      <td>5.7610</td>\n",
              "      <td>5.89</td>\n",
              "      <td>2.434</td>\n",
              "      <td>2.00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>941.0</td>\n",
              "      <td>3.800</td>\n",
              "      <td>490.15</td>\n",
              "      <td>958.15</td>\n",
              "      <td>4.79000</td>\n",
              "      <td>0.320</td>\n",
              "      <td>6.69400</td>\n",
              "      <td>37.7000</td>\n",
              "      <td>0.52000</td>\n",
              "      <td>227.0</td>\n",
              "      <td>2.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.750000</td>\n",
              "      <td>57.815474</td>\n",
              "      <td>3.375000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>5.750000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>78.375000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>1.001250</td>\n",
              "      <td>100.375000</td>\n",
              "      <td>1.087500</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>1.043750</td>\n",
              "      <td>1.178750</td>\n",
              "      <td>2.716250</td>\n",
              "      <td>2.345000</td>\n",
              "      <td>6.276225</td>\n",
              "      <td>6.097500</td>\n",
              "      <td>2.782625</td>\n",
              "      <td>2.415000</td>\n",
              "      <td>7.750000</td>\n",
              "      <td>4.375000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>2.375000</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>3.625000</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>14.00000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1049.500000</td>\n",
              "      <td>3.896500</td>\n",
              "      <td>626.825000</td>\n",
              "      <td>1088.275000</td>\n",
              "      <td>4.654465</td>\n",
              "      <td>0.589375</td>\n",
              "      <td>7.811295</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.48</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.21</td>\n",
              "      <td>3.44</td>\n",
              "      <td>3.32</td>\n",
              "      <td>8.3703</td>\n",
              "      <td>7.54</td>\n",
              "      <td>3.610</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1314.0</td>\n",
              "      <td>0.793</td>\n",
              "      <td>54.75</td>\n",
              "      <td>90.15</td>\n",
              "      <td>0.00143</td>\n",
              "      <td>0.920</td>\n",
              "      <td>0.22259</td>\n",
              "      <td>3.4099</td>\n",
              "      <td>0.02674</td>\n",
              "      <td>249.0</td>\n",
              "      <td>2.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46.750000</td>\n",
              "      <td>107.506150</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>10.750000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>64.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.660000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>1.475000</td>\n",
              "      <td>2.393750</td>\n",
              "      <td>1.550000</td>\n",
              "      <td>1.162500</td>\n",
              "      <td>1.997500</td>\n",
              "      <td>1.322500</td>\n",
              "      <td>3.836150</td>\n",
              "      <td>4.442500</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>5.525000</td>\n",
              "      <td>10.750000</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.00000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>749.250000</td>\n",
              "      <td>7.125000</td>\n",
              "      <td>1383.150000</td>\n",
              "      <td>2717.150000</td>\n",
              "      <td>10.875000</td>\n",
              "      <td>0.236250</td>\n",
              "      <td>12.875000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>144.0</td>\n",
              "      <td>1.53</td>\n",
              "      <td>2.375</td>\n",
              "      <td>1.60</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>1.07</td>\n",
              "      <td>3.8522</td>\n",
              "      <td>4.44</td>\n",
              "      <td>1.870</td>\n",
              "      <td>5.44</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>731.0</td>\n",
              "      <td>7.900</td>\n",
              "      <td>1235.15</td>\n",
              "      <td>2485.15</td>\n",
              "      <td>10.50000</td>\n",
              "      <td>0.235</td>\n",
              "      <td>11.30000</td>\n",
              "      <td>250.5800</td>\n",
              "      <td>429.00000</td>\n",
              "      <td>284.0</td>\n",
              "      <td>2.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27.125000</td>\n",
              "      <td>61.084025</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>13.125000</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>74.875000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.081250</td>\n",
              "      <td>102.750000</td>\n",
              "      <td>1.096250</td>\n",
              "      <td>1.448750</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>1.191250</td>\n",
              "      <td>2.718750</td>\n",
              "      <td>2.307500</td>\n",
              "      <td>6.088075</td>\n",
              "      <td>5.997500</td>\n",
              "      <td>2.698750</td>\n",
              "      <td>2.762500</td>\n",
              "      <td>8.125000</td>\n",
              "      <td>4.375000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.625000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.375000</td>\n",
              "      <td>14.00000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>1019.875000</td>\n",
              "      <td>4.559000</td>\n",
              "      <td>813.450000</td>\n",
              "      <td>1498.650000</td>\n",
              "      <td>5.488215</td>\n",
              "      <td>0.577875</td>\n",
              "      <td>7.348795</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.48</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.21</td>\n",
              "      <td>3.44</td>\n",
              "      <td>3.32</td>\n",
              "      <td>8.3703</td>\n",
              "      <td>7.54</td>\n",
              "      <td>3.610</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1314.0</td>\n",
              "      <td>0.793</td>\n",
              "      <td>54.75</td>\n",
              "      <td>90.15</td>\n",
              "      <td>0.00143</td>\n",
              "      <td>0.920</td>\n",
              "      <td>0.22259</td>\n",
              "      <td>3.4099</td>\n",
              "      <td>0.02674</td>\n",
              "      <td>249.0</td>\n",
              "      <td>2.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42.454545</td>\n",
              "      <td>97.547122</td>\n",
              "      <td>4.636364</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>5.272727</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>74.818182</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>1.419091</td>\n",
              "      <td>133.403704</td>\n",
              "      <td>1.400909</td>\n",
              "      <td>1.999545</td>\n",
              "      <td>1.454545</td>\n",
              "      <td>1.273636</td>\n",
              "      <td>2.180909</td>\n",
              "      <td>1.664545</td>\n",
              "      <td>4.592800</td>\n",
              "      <td>5.185455</td>\n",
              "      <td>2.089636</td>\n",
              "      <td>3.825455</td>\n",
              "      <td>9.363636</td>\n",
              "      <td>3.636364</td>\n",
              "      <td>1.363636</td>\n",
              "      <td>1.636364</td>\n",
              "      <td>8.181818</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>4.363636</td>\n",
              "      <td>1.818182</td>\n",
              "      <td>14.00000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>830.272727</td>\n",
              "      <td>6.463636</td>\n",
              "      <td>926.477273</td>\n",
              "      <td>1795.095455</td>\n",
              "      <td>7.954545</td>\n",
              "      <td>0.317545</td>\n",
              "      <td>8.925727</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>144.0</td>\n",
              "      <td>1.53</td>\n",
              "      <td>2.375</td>\n",
              "      <td>1.60</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>1.07</td>\n",
              "      <td>3.8522</td>\n",
              "      <td>4.44</td>\n",
              "      <td>1.870</td>\n",
              "      <td>5.44</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>731.0</td>\n",
              "      <td>7.900</td>\n",
              "      <td>1235.15</td>\n",
              "      <td>2485.15</td>\n",
              "      <td>10.50000</td>\n",
              "      <td>0.235</td>\n",
              "      <td>11.30000</td>\n",
              "      <td>250.5800</td>\n",
              "      <td>429.00000</td>\n",
              "      <td>284.0</td>\n",
              "      <td>2.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>24.000000</td>\n",
              "      <td>51.785333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>73.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.273333</td>\n",
              "      <td>121.333333</td>\n",
              "      <td>1.173333</td>\n",
              "      <td>1.675000</td>\n",
              "      <td>1.183333</td>\n",
              "      <td>0.573333</td>\n",
              "      <td>2.163333</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>5.047900</td>\n",
              "      <td>5.360000</td>\n",
              "      <td>2.166000</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>5.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>9.333333</td>\n",
              "      <td>14.00000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>880.000000</td>\n",
              "      <td>7.900000</td>\n",
              "      <td>965.683333</td>\n",
              "      <td>2028.616667</td>\n",
              "      <td>3.550000</td>\n",
              "      <td>0.563333</td>\n",
              "      <td>6.778333</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.88</td>\n",
              "      <td>103.0</td>\n",
              "      <td>1.02</td>\n",
              "      <td>1.100</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.43</td>\n",
              "      <td>2.58</td>\n",
              "      <td>2.65</td>\n",
              "      <td>5.8458</td>\n",
              "      <td>6.22</td>\n",
              "      <td>2.589</td>\n",
              "      <td>2.00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>2.900</td>\n",
              "      <td>385.95</td>\n",
              "      <td>717.85</td>\n",
              "      <td>2.07000</td>\n",
              "      <td>0.710</td>\n",
              "      <td>1.71750</td>\n",
              "      <td>9.8000</td>\n",
              "      <td>0.26900</td>\n",
              "      <td>279.0</td>\n",
              "      <td>2.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>45.000000</td>\n",
              "      <td>104.684667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>61.666667</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.723333</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>1.373333</td>\n",
              "      <td>2.398333</td>\n",
              "      <td>1.433333</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>1.860000</td>\n",
              "      <td>1.936667</td>\n",
              "      <td>4.038067</td>\n",
              "      <td>4.330000</td>\n",
              "      <td>1.614667</td>\n",
              "      <td>4.260000</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.333333</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>14.00000</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>728.000000</td>\n",
              "      <td>11.366667</td>\n",
              "      <td>1870.816667</td>\n",
              "      <td>3682.150000</td>\n",
              "      <td>8.533333</td>\n",
              "      <td>0.239333</td>\n",
              "      <td>20.256667</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.33</td>\n",
              "      <td>134.0</td>\n",
              "      <td>1.26</td>\n",
              "      <td>1.765</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.82</td>\n",
              "      <td>1.33</td>\n",
              "      <td>1.70</td>\n",
              "      <td>3.4521</td>\n",
              "      <td>3.64</td>\n",
              "      <td>1.320</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>640.0</td>\n",
              "      <td>6.600</td>\n",
              "      <td>904.15</td>\n",
              "      <td>2223.15</td>\n",
              "      <td>6.51000</td>\n",
              "      <td>0.210</td>\n",
              "      <td>16.90000</td>\n",
              "      <td>77.1400</td>\n",
              "      <td>22.70000</td>\n",
              "      <td>262.0</td>\n",
              "      <td>2.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>85.092000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66.500000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.545000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>1.320000</td>\n",
              "      <td>2.055000</td>\n",
              "      <td>1.350000</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>1.940000</td>\n",
              "      <td>2.120000</td>\n",
              "      <td>4.606550</td>\n",
              "      <td>4.765000</td>\n",
              "      <td>1.877000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>14.00000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>790.500000</td>\n",
              "      <td>10.850000</td>\n",
              "      <td>1307.650000</td>\n",
              "      <td>2804.150000</td>\n",
              "      <td>5.650000</td>\n",
              "      <td>0.295000</td>\n",
              "      <td>11.797000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.03</td>\n",
              "      <td>118.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>1.285</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.33</td>\n",
              "      <td>1.70</td>\n",
              "      <td>3.4521</td>\n",
              "      <td>3.64</td>\n",
              "      <td>1.320</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>640.0</td>\n",
              "      <td>3.800</td>\n",
              "      <td>490.15</td>\n",
              "      <td>958.15</td>\n",
              "      <td>4.79000</td>\n",
              "      <td>0.270</td>\n",
              "      <td>6.69400</td>\n",
              "      <td>37.7000</td>\n",
              "      <td>0.52000</td>\n",
              "      <td>227.0</td>\n",
              "      <td>2.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>22.666667</td>\n",
              "      <td>49.131667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>10.666667</td>\n",
              "      <td>5.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.426667</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>1.233333</td>\n",
              "      <td>1.888333</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.553333</td>\n",
              "      <td>1.710000</td>\n",
              "      <td>1.886667</td>\n",
              "      <td>3.940833</td>\n",
              "      <td>4.393333</td>\n",
              "      <td>1.717333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>9.333333</td>\n",
              "      <td>14.00000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>738.000000</td>\n",
              "      <td>9.566667</td>\n",
              "      <td>1830.483333</td>\n",
              "      <td>3302.150000</td>\n",
              "      <td>3.723333</td>\n",
              "      <td>0.563333</td>\n",
              "      <td>39.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.11</td>\n",
              "      <td>110.0</td>\n",
              "      <td>1.11</td>\n",
              "      <td>1.420</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.90</td>\n",
              "      <td>1.98</td>\n",
              "      <td>4.1852</td>\n",
              "      <td>4.77</td>\n",
              "      <td>1.916</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>787.0</td>\n",
              "      <td>5.400</td>\n",
              "      <td>1683.15</td>\n",
              "      <td>2628.15</td>\n",
              "      <td>2.33000</td>\n",
              "      <td>0.710</td>\n",
              "      <td>50.55000</td>\n",
              "      <td>384.2200</td>\n",
              "      <td>148.00000</td>\n",
              "      <td>452.0</td>\n",
              "      <td>4.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>50.745850</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.250000</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.515000</td>\n",
              "      <td>126.500000</td>\n",
              "      <td>1.232500</td>\n",
              "      <td>2.112500</td>\n",
              "      <td>1.237500</td>\n",
              "      <td>0.892500</td>\n",
              "      <td>1.962500</td>\n",
              "      <td>2.185000</td>\n",
              "      <td>4.523550</td>\n",
              "      <td>4.520000</td>\n",
              "      <td>1.922500</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>14.00000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>818.000000</td>\n",
              "      <td>11.973250</td>\n",
              "      <td>1511.550000</td>\n",
              "      <td>2965.150000</td>\n",
              "      <td>3.897857</td>\n",
              "      <td>0.557500</td>\n",
              "      <td>12.005647</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.76</td>\n",
              "      <td>142.0</td>\n",
              "      <td>1.36</td>\n",
              "      <td>2.580</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.54</td>\n",
              "      <td>1.86</td>\n",
              "      <td>3.1359</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1.380</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>659.0</td>\n",
              "      <td>14.600</td>\n",
              "      <td>1933.15</td>\n",
              "      <td>3560.15</td>\n",
              "      <td>4.54000</td>\n",
              "      <td>0.520</td>\n",
              "      <td>15.45000</td>\n",
              "      <td>421.0000</td>\n",
              "      <td>21.90000</td>\n",
              "      <td>470.0</td>\n",
              "      <td>4.85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>985 rows × 264 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47df7bdd-c8f9-4c54-8da3-864c081af92c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47df7bdd-c8f9-4c54-8da3-864c081af92c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47df7bdd-c8f9-4c54-8da3-864c081af92c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     avg_Atomic_Number  ...  mode_Cohesive_energy\n",
              "0            46.206897  ...                  2.46\n",
              "1            25.750000  ...                  2.62\n",
              "2            46.750000  ...                  2.95\n",
              "3            27.125000  ...                  2.62\n",
              "4            42.454545  ...                  2.95\n",
              "..                 ...  ...                   ...\n",
              "980          24.000000  ...                  2.85\n",
              "981          45.000000  ...                  2.75\n",
              "982          37.000000  ...                  2.46\n",
              "983          22.666667  ...                  4.63\n",
              "984          23.000000  ...                  4.85\n",
              "\n",
              "[985 rows x 264 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X_test, y_test, _, _ = generate_features(test_df)\n",
        "X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuEoRyF_iRsV"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq79CBx_iVnl"
      },
      "source": [
        "We can do hyperparameter tuning in different ways. Two common ways are grid search (less efficient) and random search (more efficient). Below are examples taken/modified from the website https://www.geeksforgeeks.org/hyperparameter-tuning/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7DpTTU0FV8vI",
        "outputId": "1157a51d-ba66-42aa-a173-71329c8df3b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid tuned Logistic Regression Parameters: {'C': 19306.977288832535}\n",
            "Best score is 0.8191010003934494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "#Grid search first using logistic regression classifier model\n",
        "\n",
        "# Creating the hyperparameter grid\n",
        "c_space = np.logspace(-5, 8, 15)\n",
        "param_grid = {'C': c_space}\n",
        "  \n",
        "# Instantiating logistic regression classifier\n",
        "# https://stats.stackexchange.com/a/184026/293880\n",
        "logreg = LogisticRegression(max_iter=100)\n",
        "  \n",
        "# Instantiating the GridSearchCV object\n",
        "logreg_grid = GridSearchCV(logreg, param_grid, cv = 5)\n",
        "  \n",
        "logreg_grid.fit(X_train, y_train)\n",
        "  \n",
        "# Print the tuned parameters and score\n",
        "print(\"Grid tuned Logistic Regression Parameters: {}\".format(logreg_grid.best_params_)) \n",
        "print(\"Best score is {}\".format(logreg_grid.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HtZMtOBiV8vJ",
        "outputId": "1e27eb3b-6675-4a83-8f44-332994b4eba9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random tuned Logistic Regression Parameters: {'C': 3}\n",
            "Best score is 0.820117841317346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "#Now we can try random search with logistic regression\n",
        "  \n",
        "# Creating the hyperparameter grid \n",
        "param_dist = {\"C\": randint(-5,15)}\n",
        "  \n",
        "# Instantiating Decision Tree classifier\n",
        "logreg = LogisticRegression()\n",
        "  \n",
        "# Instantiating RandomizedSearchCV object\n",
        "logreg_random = RandomizedSearchCV(logreg, param_dist, cv = 5)\n",
        "  \n",
        "logreg_random.fit(X_train, y_train)\n",
        "  \n",
        "# Print the tuned parameters and score\n",
        "print(\"Random tuned Logistic Regression Parameters: {}\".format(logreg_random.best_params_))\n",
        "print(\"Best score is {}\".format(logreg_random.best_score_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0jdvkp_V8vJ"
      },
      "source": [
        "We can do the same grid vs random search with another model, like a decision tree classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lwxtaSddV8vJ",
        "outputId": "5a4832af-c902-4d12-a67a-eb50f9e31648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid tuned Decision Tree Parameters: {'criterion': 'gini', 'max_depth': 6, 'max_features': 7, 'min_samples_leaf': 5}\n",
            "Best score is 0.850099652345539\n"
          ]
        }
      ],
      "source": [
        "#grid search for decision tree hyperparameters\n",
        "  \n",
        "# Creating the hyperparameter grid \n",
        "param_grid = {\"max_depth\": range(1,10),\n",
        "              \"max_features\": range(1,10),\n",
        "              \"min_samples_leaf\": range(1,10),\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "\n",
        "# Instantiating Decision Tree classifier\n",
        "tree = DecisionTreeClassifier()\n",
        "  \n",
        "# Instantiating GridSearchCV object\n",
        "tree_grid = GridSearchCV(tree, param_grid, cv = 5)\n",
        "  \n",
        "tree_grid.fit(X_train, y_train)\n",
        "  \n",
        "# Print the tuned parameters and score\n",
        "print(\"Grid tuned Decision Tree Parameters: {}\".format(tree_grid.best_params_))\n",
        "print(\"Best score is {}\".format(tree_grid.best_score_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NdIPhe3WV8vK",
        "outputId": "10490388-2cca-4416-c249-a249e44d161c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 8, 'max_features': 5, 'min_samples_leaf': 6}\n",
            "Best score is 0.8219051335470429\n"
          ]
        }
      ],
      "source": [
        "#random search for decision tree hyperparameters\n",
        "  \n",
        "# Creating the hyperparameter grid \n",
        "param_dist = {\"max_depth\": randint(1,10),\n",
        "              \"max_features\": randint(1,10),\n",
        "              \"min_samples_leaf\": randint(1,10),\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "\n",
        "# Instantiating Decision Tree classifier\n",
        "tree = DecisionTreeClassifier()\n",
        "  \n",
        "# Instantiating RandomizedSearchCV object\n",
        "tree_random = RandomizedSearchCV(tree, param_dist, cv = 5)\n",
        "  \n",
        "tree_random.fit(X_train, y_train)\n",
        "  \n",
        "# Print the tuned parameters and score\n",
        "print(\"Random tuned Decision Tree Parameters: {}\".format(tree_random.best_params_))\n",
        "print(\"Best score is {}\".format(tree_random.best_score_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBXW3O6phXtl"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8yrOCrj7hXY1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Graveyard"
      ],
      "metadata": {
        "id": "YgcnmD4FcGUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# scaler.fit(X_train)\n",
        "# X_train = scaler.transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "# X_train"
      ],
      "metadata": {
        "id": "_OCT4yE_cJgo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "materials_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}