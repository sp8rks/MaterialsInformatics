{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sp8rks/MaterialsInformatics/blob/main/worked_examples/foundry/foundry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundry\n",
    "\n",
    "Foundry is an easy-to-use API that allows the use to access a bunch of material science datasets. The data can be loaded very efficiently and without much hassle. This notebook will be similar to deepchem_pubchempy and MP_API in that it will be focused on showing how to access and play around with the datasets.\n",
    "\n",
    "#### Video (general material databases)\n",
    "\n",
    "https://www.youtube.com/watch?v=cdSENQPsAiI&list=PLL0SWcFqypCl4lrzk1dMWwTUrzQZFt7y0&index=7 (Materials Data Repositories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from foundry import Foundry\n",
    "f = Foundry()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foundry_g4mp2_solvation_v1.2</td>\n",
       "      <td>DFT Estimates of Solvation Energy in Multiple ...</td>\n",
       "      <td>root=2022</td>\n",
       "      <td>10.18126/jos5-wj65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dataset_name  \\\n",
       "0  foundry_g4mp2_solvation_v1.2   \n",
       "\n",
       "                                               title       year  \\\n",
       "0  DFT Estimates of Solvation Energy in Multiple ...  root=2022   \n",
       "\n",
       "                  DOI                                     FoundryDataset  \n",
       "0  10.18126/jos5-wj65  <foundry.foundry_dataset.FoundryDataset object...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for band gap datasets\n",
    "results = f.search(\"band gap\", limit=5)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading \n",
    "\n",
    "Let's load the first dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: foundry_g4mp2_solvation_v1.2\n",
      "Title: DFT Estimates of Solvation Energy in Multiple Solvents\n",
      "DOI: root='10.18126/jos5-wj65'\n",
      "Data Type: tabular\n"
     ]
    }
   ],
   "source": [
    "# Get a dataset\n",
    "results = f.search(\"band gap\", limit=1)\n",
    "dataset = results.iloc[0].FoundryDataset\n",
    "\n",
    "# Get the schema\n",
    "schema = dataset.get_schema()\n",
    "\n",
    "print(f\"Dataset: {schema['name']}\")\n",
    "print(f\"Title: {schema['title']}\")\n",
    "print(f\"DOI: {schema['doi']}\")\n",
    "print(f\"Data Type: {schema['data_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields:\n",
      "------------------------------------------------------------\n",
      "  [input ] smiles_0: Input SMILES string \n",
      "  [input ] smiles_1: SMILES string after relaxation \n",
      "  [input ] inchi_0: InChi after generating coordinates with CORINA \n",
      "  [input ] inchi_1: InChi after relaxation \n",
      "  [input ] xyz: InChi after relaxation (XYZ coordinates after relaxation)\n",
      "  [input ] atomic_charges: Atomic charges on each atom, as predicted from B3LYP \n",
      "  [input ] A: Rotational constant, A (GHz)\n",
      "  [input ] B: Rotational constant, B (GHz)\n",
      "  [input ] C: Rotational constant, C (GHz)\n",
      "  [input ] inchi_1: InChi after relaxation \n",
      "  [input ] n_electrons: Number of electrons \n",
      "  [input ] n_heavy_atoms: Number of non-hydrogen atoms \n",
      "  [input ] n_atom: Number of atoms in molecule \n",
      "  [input ] mu: Dipole moment (D)\n",
      "  [input ] alpha: Isotropic polarizability (a_0^3)\n",
      "  [input ] R2: Electronic spatial extant (a_0^2)\n",
      "  [input ] cv: Heat capacity at 298.15K (cal/mol-K)\n",
      "  [target] g4mp2_hf298: G4MP2 Standard Enthalpy of Formation, 298K (kcal/mol)\n",
      "  [input ] bandgap: B3LYP Band gap energy (Ha)\n",
      "  [input ] homo: B3LYP Energy of HOMO (Ha)\n",
      "  [input ] lumo: B3LYP Energy of LUMO (Ha)\n",
      "  [input ] zpe: B3LYP Zero point vibrational energy (Ha)\n",
      "  [input ] u0: B3LYP Internal energy at 0K (Ha)\n",
      "  [input ] u: B3LYP Internal energy at 298.15K (Ha)\n",
      "  [input ] h: B3LYP Enthalpy at 298.15K (Ha)\n",
      "  [input ] u0_atom: B3LYP atomization energy at 0K (Ha)\n",
      "  [input ] g: B3LYP Free energy at 298.15K (Ha)\n",
      "  [target] g4mp2_0k: G4MP2 Internal energy at 0K (Ha)\n",
      "  [target] g4mp2_energy: G4MP2 Internal energy at 298.15K (Ha)\n",
      "  [target] g4mp2_enthalpy: G4MP2 Enthalpy at 298.15K (Ha)\n",
      "  [target] g4mp2_free: G4MP2 Free eergy at 0K (Ha)\n",
      "  [target] g4mp2_atom: G4MP2 atomization energy at 0K (Ha)\n",
      "  [target] sol_acetone: Solvation energy, acetone (kcal/mol)\n",
      "  [target] sol_acn: Solvation energy, acetonitrile (kcal/mol)\n",
      "  [target] sol_dmso: Solvation energy, dimethyl sulfoxide (kcal/mol)\n",
      "  [target] sol_ethanol: Solvation energy, ethanol (kcal/mol)\n",
      "  [target] sol_water: Solvation energy, water (kcal/mol)\n",
      "Splits:\n",
      "------------------------------------------------------------\n",
      "  - train: train\n"
     ]
    }
   ],
   "source": [
    "# Examine fields (columns)\n",
    "print(\"Fields:\")\n",
    "print(\"-\" * 60)\n",
    "for field in schema['fields']:\n",
    "    role = field['role']  # 'input' or 'target'\n",
    "    name = field['name']\n",
    "    desc = field['description'] or 'No description'\n",
    "    units = field['units'] or ''\n",
    "    print(f\"  [{role:6}] {name}: {desc} {f'({units})' if units else ''}\")\n",
    "\n",
    "# Examine splits (train/test/validation)\n",
    "print(\"Splits:\")\n",
    "print(\"-\" * 60)\n",
    "for split in schema['splits']:\n",
    "    print(f\"  - {split['name']}: {split.get('type', 'data')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can load our dataset. This can be done in a few different ways. Firstly, you can use f.list() to print off all the avaiable datasets. The other option is to browse their website https://foundry-ml.org/#/datasets or https://www.materialsdatafacility.org/portal which has a very nice UI for finding them. \n",
    "\n",
    "After you have an idea of the dataset that you want you can either copy and paste in the doi from the website or search it within python.\n",
    "\n",
    "If you do not know the doi of the dataset it can be found by searching the name of the datasets as shown. For this notebook we will use the 'Predicting the thermodynamic stability of perovskite oxides using machine learning models' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add cell here to loady via DOI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a specific split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TransferAPIError",
     "evalue": "('GET', 'https://transfer.api.globus.org/v0.10/operation/endpoint/82f1b5c6-6e9b-11e5-ba47-22000b92c6ec/ls?path=%2Ffoundry%2Ffoundry_g4mp2_solvation_v1.2%2F', 'Bearer', 502, 'ExternalError.DirListingFailed.Timeout', 'Command Failed: Error (connect)\\nEndpoint: globuspublish#mdf-publications (82f1b5c6-6e9b-11e5-ba47-22000b92c6ec)\\nServer: 141.142.218.119:443\\nMessage: The operation timed out\\n', 'CIMLI4ZVK')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTransferAPIError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load only training data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_data = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_as_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining data keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_data.keys()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28misinstance\u001b[39m(train_data,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mdict\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mtype\u001b[39m(train_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\foundry\\foundry_dataset.py:75\u001b[39m, in \u001b[36mFoundryDataset.get_as_dict\u001b[39m\u001b[34m(self, split, as_hdf5, include_schema)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_as_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, split: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m, as_hdf5: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m, include_schema: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns the data from the dataset as a dictionary\u001b[39;00m\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m \u001b[33;03m    Arguments:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m \n\u001b[32m     74\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_foundry_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_as_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfoundry_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m                                            \u001b[49m\u001b[43mas_hdf5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m include_schema:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     81\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m: data,\n\u001b[32m     82\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mschema\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.get_schema(),\n\u001b[32m     83\u001b[39m         }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\foundry\\foundry_cache.py:205\u001b[39m, in \u001b[36mFoundryCache.load_as_dict\u001b[39m\u001b[34m(self, split, dataset_name, foundry_schema, as_hdf5)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[33;03mLoad the data associated with the specified dataset and return it as a labeled dictionary of tuples.\u001b[39;00m\n\u001b[32m    194\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m \u001b[33;03m    dict: A labeled dictionary of tuples containing the loaded data.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# Ensure local copy of data is available\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload_to_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mfoundry_schema\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m data = {}\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# Handle splits if they exist. Return as a labeled dictionary of tuples\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\foundry\\foundry_cache.py:75\u001b[39m, in \u001b[36mFoundryCache.download_to_cache\u001b[39m\u001b[34m(self, dataset_name, splits)\u001b[39m\n\u001b[32m     73\u001b[39m         \u001b[38;5;28mself\u001b[39m.download_via_globus(dataset_name)\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload_via_http\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m.validate_local_dataset_storage(dataset_name, splits)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\foundry\\foundry_cache.py:122\u001b[39m, in \u001b[36mFoundryCache.download_via_http\u001b[39m\u001b[34m(self, dataset_name)\u001b[39m\n\u001b[32m    115\u001b[39m task_generator = recursive_ls(\u001b[38;5;28mself\u001b[39m.transfer_client,\n\u001b[32m    116\u001b[39m                               https_config[\u001b[33m'\u001b[39m\u001b[33msource_ep_id\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    117\u001b[39m                               https_config[\u001b[33m'\u001b[39m\u001b[33mfolder_to_crawl\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(\u001b[38;5;28mself\u001b[39m.parallel_https) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# First submit all files\u001b[39;00m\n\u001b[32m    121\u001b[39m     futures = \u001b[43m[\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocal_cache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttps_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[43m               \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFinding files\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# Check that they completed successfully\u001b[39;00m\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m tqdm(as_completed(futures), disable=\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose, desc=\u001b[33m\"\u001b[39m\u001b[33mDownloading files\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\tqdm\\std.py:1169\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m# If the bar is disabled, then just walk the iterable\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m# (note: keep this check outside the loop for performance)\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.disable:\n\u001b[32m-> \u001b[39m\u001b[32m1169\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\foundry\\https_download.py:32\u001b[39m, in \u001b[36mrecursive_ls\u001b[39m\u001b[34m(tc, ep, path, max_depth)\u001b[39m\n\u001b[32m     30\u001b[39m queue = deque()\n\u001b[32m     31\u001b[39m queue.append((path, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m _get_files(tc, ep, queue, max_depth)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\foundry\\https_download.py:40\u001b[39m, in \u001b[36m_get_files\u001b[39m\u001b[34m(tc, ep, queue, max_depth)\u001b[39m\n\u001b[32m     37\u001b[39m abs_path, rel_path, depth = queue.pop()\n\u001b[32m     38\u001b[39m path_prefix = rel_path + \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rel_path \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m res = \u001b[43mtc\u001b[49m\u001b[43m.\u001b[49m\u001b[43moperation_ls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mabs_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m depth < max_depth:\n\u001b[32m     43\u001b[39m     queue.extend(\n\u001b[32m     44\u001b[39m         (\n\u001b[32m     45\u001b[39m             res[\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m] + item[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mdir\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     51\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\globus_sdk\\services\\transfer\\client.py:1378\u001b[39m, in \u001b[36mTransferClient.operation_ls\u001b[39m\u001b[34m(self, endpoint_id, path, show_hidden, orderby, limit, offset, filter, local_user, query_params)\u001b[39m\n\u001b[32m   1374\u001b[39m     query_params[\u001b[33m\"\u001b[39m\u001b[33mlocal_user\u001b[39m\u001b[33m\"\u001b[39m] = local_user\n\u001b[32m   1376\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTransferClient.operation_ls(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m IterableTransferResponse(\n\u001b[32m-> \u001b[39m\u001b[32m1378\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moperation/endpoint/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/ls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1379\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\globus_sdk\\client.py:334\u001b[39m, in \u001b[36mBaseClient.get\u001b[39m\u001b[34m(self, path, query_params, headers, automatic_authorization)\u001b[39m\n\u001b[32m    328\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    329\u001b[39m \u001b[33;03mMake a GET request to the specified path.\u001b[39;00m\n\u001b[32m    330\u001b[39m \n\u001b[32m    331\u001b[39m \u001b[33;03mSee :py:meth:`~.BaseClient.request` for details on the various parameters.\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    333\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGET to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with query_params \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mautomatic_authorization\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautomatic_authorization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\globus_sdk\\client.py:522\u001b[39m, in \u001b[36mBaseClient.request\u001b[39m\u001b[34m(self, method, path, query_params, data, headers, encoding, allow_redirects, stream, automatic_authorization)\u001b[39m\n\u001b[32m    519\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GlobusHTTPResponse(r, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    521\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrequest completed with (error) response code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error_class(r)\n",
      "\u001b[31mTransferAPIError\u001b[39m: ('GET', 'https://transfer.api.globus.org/v0.10/operation/endpoint/82f1b5c6-6e9b-11e5-ba47-22000b92c6ec/ls?path=%2Ffoundry%2Ffoundry_g4mp2_solvation_v1.2%2F', 'Bearer', 502, 'ExternalError.DirListingFailed.Timeout', 'Command Failed: Error (connect)\\nEndpoint: globuspublish#mdf-publications (82f1b5c6-6e9b-11e5-ba47-22000b92c6ec)\\nServer: 141.142.218.119:443\\nMessage: The operation timed out\\n', 'CIMLI4ZVK')"
     ]
    }
   ],
   "source": [
    "# Load only training data\n",
    "train_data = dataset.get_as_dict(split='train')\n",
    "print(f\"Training data keys: {train_data.keys() if isinstance(train_data, dict) else type(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load all splits at once\n",
    "all_data = dataset.get_as_dict()\n",
    "print(f\"All splits: {list(all_data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load data with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TransferAPIError",
     "evalue": "('GET', 'https://transfer.api.globus.org/v0.10/operation/endpoint/82f1b5c6-6e9b-11e5-ba47-22000b92c6ec/ls?path=%2Ffoundry%2Ffoundry_g4mp2_solvation_v1.2%2F', 'Bearer', 502, 'ExternalError.DirListingFailed.Timeout', 'Command Failed: Error (connect)\\nEndpoint: globuspublish#mdf-publications (82f1b5c6-6e9b-11e5-ba47-22000b92c6ec)\\nServer: 141.142.218.119:443\\nMessage: The operation timed out\\n', 'jknfL492i')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTransferAPIError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get data with schema attached\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_as_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResult keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.keys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSchema name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mschema\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\foundry\\foundry_dataset.py:75\u001b[39m, in \u001b[36mFoundryDataset.get_as_dict\u001b[39m\u001b[34m(self, split, as_hdf5, include_schema)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_as_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, split: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m, as_hdf5: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m, include_schema: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns the data from the dataset as a dictionary\u001b[39;00m\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m \u001b[33;03m    Arguments:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m \n\u001b[32m     74\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_foundry_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_as_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfoundry_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m                                            \u001b[49m\u001b[43mas_hdf5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m include_schema:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     81\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m: data,\n\u001b[32m     82\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mschema\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.get_schema(),\n\u001b[32m     83\u001b[39m         }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\foundry\\foundry_cache.py:205\u001b[39m, in \u001b[36mFoundryCache.load_as_dict\u001b[39m\u001b[34m(self, split, dataset_name, foundry_schema, as_hdf5)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[33;03mLoad the data associated with the specified dataset and return it as a labeled dictionary of tuples.\u001b[39;00m\n\u001b[32m    194\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m \u001b[33;03m    dict: A labeled dictionary of tuples containing the loaded data.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# Ensure local copy of data is available\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload_to_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mfoundry_schema\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m data = {}\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# Handle splits if they exist. Return as a labeled dictionary of tuples\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\foundry\\foundry_cache.py:75\u001b[39m, in \u001b[36mFoundryCache.download_to_cache\u001b[39m\u001b[34m(self, dataset_name, splits)\u001b[39m\n\u001b[32m     73\u001b[39m         \u001b[38;5;28mself\u001b[39m.download_via_globus(dataset_name)\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload_via_http\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m.validate_local_dataset_storage(dataset_name, splits)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\foundry\\foundry_cache.py:122\u001b[39m, in \u001b[36mFoundryCache.download_via_http\u001b[39m\u001b[34m(self, dataset_name)\u001b[39m\n\u001b[32m    115\u001b[39m task_generator = recursive_ls(\u001b[38;5;28mself\u001b[39m.transfer_client,\n\u001b[32m    116\u001b[39m                               https_config[\u001b[33m'\u001b[39m\u001b[33msource_ep_id\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    117\u001b[39m                               https_config[\u001b[33m'\u001b[39m\u001b[33mfolder_to_crawl\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(\u001b[38;5;28mself\u001b[39m.parallel_https) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# First submit all files\u001b[39;00m\n\u001b[32m    121\u001b[39m     futures = \u001b[43m[\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocal_cache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttps_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[43m               \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFinding files\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# Check that they completed successfully\u001b[39;00m\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m tqdm(as_completed(futures), disable=\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose, desc=\u001b[33m\"\u001b[39m\u001b[33mDownloading files\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\tqdm\\std.py:1169\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m# If the bar is disabled, then just walk the iterable\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m# (note: keep this check outside the loop for performance)\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.disable:\n\u001b[32m-> \u001b[39m\u001b[32m1169\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\foundry\\https_download.py:32\u001b[39m, in \u001b[36mrecursive_ls\u001b[39m\u001b[34m(tc, ep, path, max_depth)\u001b[39m\n\u001b[32m     30\u001b[39m queue = deque()\n\u001b[32m     31\u001b[39m queue.append((path, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m _get_files(tc, ep, queue, max_depth)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\foundry\\https_download.py:40\u001b[39m, in \u001b[36m_get_files\u001b[39m\u001b[34m(tc, ep, queue, max_depth)\u001b[39m\n\u001b[32m     37\u001b[39m abs_path, rel_path, depth = queue.pop()\n\u001b[32m     38\u001b[39m path_prefix = rel_path + \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rel_path \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m res = \u001b[43mtc\u001b[49m\u001b[43m.\u001b[49m\u001b[43moperation_ls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mabs_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m depth < max_depth:\n\u001b[32m     43\u001b[39m     queue.extend(\n\u001b[32m     44\u001b[39m         (\n\u001b[32m     45\u001b[39m             res[\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m] + item[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mdir\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     51\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\globus_sdk\\services\\transfer\\client.py:1378\u001b[39m, in \u001b[36mTransferClient.operation_ls\u001b[39m\u001b[34m(self, endpoint_id, path, show_hidden, orderby, limit, offset, filter, local_user, query_params)\u001b[39m\n\u001b[32m   1374\u001b[39m     query_params[\u001b[33m\"\u001b[39m\u001b[33mlocal_user\u001b[39m\u001b[33m\"\u001b[39m] = local_user\n\u001b[32m   1376\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTransferClient.operation_ls(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m IterableTransferResponse(\n\u001b[32m-> \u001b[39m\u001b[32m1378\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moperation/endpoint/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/ls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1379\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\globus_sdk\\client.py:334\u001b[39m, in \u001b[36mBaseClient.get\u001b[39m\u001b[34m(self, path, query_params, headers, automatic_authorization)\u001b[39m\n\u001b[32m    328\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    329\u001b[39m \u001b[33;03mMake a GET request to the specified path.\u001b[39;00m\n\u001b[32m    330\u001b[39m \n\u001b[32m    331\u001b[39m \u001b[33;03mSee :py:meth:`~.BaseClient.request` for details on the various parameters.\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    333\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGET to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with query_params \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mautomatic_authorization\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautomatic_authorization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\uv_venvs\\foundry\\Lib\\site-packages\\globus_sdk\\client.py:522\u001b[39m, in \u001b[36mBaseClient.request\u001b[39m\u001b[34m(self, method, path, query_params, data, headers, encoding, allow_redirects, stream, automatic_authorization)\u001b[39m\n\u001b[32m    519\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GlobusHTTPResponse(r, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    521\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrequest completed with (error) response code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error_class(r)\n",
      "\u001b[31mTransferAPIError\u001b[39m: ('GET', 'https://transfer.api.globus.org/v0.10/operation/endpoint/82f1b5c6-6e9b-11e5-ba47-22000b92c6ec/ls?path=%2Ffoundry%2Ffoundry_g4mp2_solvation_v1.2%2F', 'Bearer', 502, 'ExternalError.DirListingFailed.Timeout', 'Command Failed: Error (connect)\\nEndpoint: globuspublish#mdf-publications (82f1b5c6-6e9b-11e5-ba47-22000b92c6ec)\\nServer: 141.142.218.119:443\\nMessage: The operation timed out\\n', 'jknfL492i')"
     ]
    }
   ],
   "source": [
    "# Get data with schema attached\n",
    "result = dataset.get_as_dict(include_schema=True)\n",
    "\n",
    "print(f\"Result keys: {result.keys()}\")\n",
    "print(f\"\\nSchema name: {result['schema']['name']}\")\n",
    "print(f\"Data splits: {list(result['data'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading it we have to assign it to variables which will download it. Just as a warning, some of these datasets can be quite large (300mb+) so it's worth checking out the dataset on the website before downloading it. This dataset is only 8.29 MB but it's something to be aware of. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_mp, y_mp = data.get_as_dict()['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded our data we can inspect it and see what the data contains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_mp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset only contains one input value (formula) but we can featurize it to get more inputs to train on. This is a very simple dataset (one input, one output) but the datasets available can get quite large. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It Yourself!\n",
    "\n",
    "- Use the foundry API to grab the 'Charting the complete elastic properties of inorganic crystalline compounds' dataset\n",
    "- Load the data and inspect it for what it contains\n",
    "- Featurize the formula column and create a dataframe with those features, nsites, space group, and volume\n",
    "- Assign the target variable to be the average bulk modulus \n",
    "- create train/test splits, standardize the data, and train a random forest model predicting average bulk modulus (K_Voigt)\n",
    "- score it using mean squared error, mean average error, and R2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
